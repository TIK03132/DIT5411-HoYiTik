{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7f9b07-1d8c-4e79-87c3-e83bc71de75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "GPU: []\n",
      "Selected 200 character folders (first 10):\n",
      "['1', '10', '100', '1000', '10000', '10001', '10002', '10003', '10004', '10005']\n",
      "\n",
      "Loading 200 classes …\n",
      "  [SKIP] 10020 – <40 images\n",
      "Valid classes: 199\n",
      "Train: (7960, 64, 64, 1)  Test: (3428, 64, 64, 1)\n",
      "Augmenting to 200 samples per class …\n",
      "Final train: (39800, 64, 64, 1)  (200 per class)\n",
      "\n",
      "==================== TRAINING CNN2 ====================\n",
      "Epoch 1/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0044 - loss: 5.3124\n",
      "Epoch 1: val_accuracy improved from None to 0.00503, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn2_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 18ms/step - accuracy: 0.0036 - loss: 5.2977 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 2/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0053 - loss: 5.2960\n",
      "Epoch 2: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 18ms/step - accuracy: 0.0039 - loss: 5.2950 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 3/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0040 - loss: 5.2941\n",
      "Epoch 3: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.0034 - loss: 5.2945 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 4/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0037 - loss: 5.2943\n",
      "Epoch 4: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.0034 - loss: 5.2945 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 5/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0037 - loss: 5.2944\n",
      "Epoch 5: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.0034 - loss: 5.2945 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 6/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0038 - loss: 5.2944\n",
      "Epoch 6: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.0036 - loss: 5.2945 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 6: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "cnn2 → Test Accuracy: 0.5251%\n",
      "\n",
      "==================== TRAINING CNN3 ====================\n",
      "Epoch 1/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0276 - loss: 4.9971\n",
      "Epoch 1: val_accuracy improved from None to 0.19447, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn3_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 20ms/step - accuracy: 0.0779 - loss: 4.3944 - val_accuracy: 0.1945 - val_loss: 3.4246\n",
      "Epoch 2/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3235 - loss: 2.5467\n",
      "Epoch 2: val_accuracy improved from 0.19447 to 0.59686, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn3_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.4079 - loss: 2.1644 - val_accuracy: 0.5969 - val_loss: 1.3987\n",
      "Epoch 3/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5935 - loss: 1.3738\n",
      "Epoch 3: val_accuracy did not improve from 0.59686\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.6282 - loss: 1.2428 - val_accuracy: 0.5574 - val_loss: 1.5551\n",
      "Epoch 4/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7116 - loss: 0.9347\n",
      "Epoch 4: val_accuracy did not improve from 0.59686\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.7279 - loss: 0.8799 - val_accuracy: 0.4143 - val_loss: 2.3495\n",
      "Epoch 5/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7679 - loss: 0.7247\n",
      "Epoch 5: val_accuracy did not improve from 0.59686\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.7796 - loss: 0.6923 - val_accuracy: 0.5578 - val_loss: 1.7169\n",
      "Epoch 6/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8096 - loss: 0.5910\n",
      "Epoch 6: val_accuracy improved from 0.59686 to 0.75138, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn3_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8155 - loss: 0.5715 - val_accuracy: 0.7514 - val_loss: 0.8373\n",
      "Epoch 7/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8366 - loss: 0.5005\n",
      "Epoch 7: val_accuracy did not improve from 0.75138\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.8408 - loss: 0.4846 - val_accuracy: 0.4382 - val_loss: 3.0251\n",
      "Epoch 8/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8521 - loss: 0.4540\n",
      "Epoch 8: val_accuracy did not improve from 0.75138\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.8587 - loss: 0.4372 - val_accuracy: 0.7124 - val_loss: 1.0131\n",
      "Epoch 9/12\n",
      "\u001b[1m993/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8678 - loss: 0.4016\n",
      "Epoch 9: val_accuracy did not improve from 0.75138\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 20ms/step - accuracy: 0.8730 - loss: 0.3893 - val_accuracy: 0.1406 - val_loss: 6.5761\n",
      "Epoch 10/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8809 - loss: 0.3617\n",
      "Epoch 10: val_accuracy did not improve from 0.75138\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.8856 - loss: 0.3488 - val_accuracy: 0.5592 - val_loss: 2.2169\n",
      "Epoch 11/12\n",
      "\u001b[1m994/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8932 - loss: 0.3265\n",
      "Epoch 11: val_accuracy did not improve from 0.75138\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 19ms/step - accuracy: 0.8943 - loss: 0.3211 - val_accuracy: 0.5839 - val_loss: 1.6136\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "cnn3 → Test Accuracy: 59.0140%\n",
      "\n",
      "==================== TRAINING CNN_RES ====================\n",
      "Epoch 1/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0047 - loss: 5.3036\n",
      "Epoch 1: val_accuracy improved from None to 0.00490, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn_res_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 30ms/step - accuracy: 0.0043 - loss: 5.2970 - val_accuracy: 0.0049 - val_loss: 5.2933\n",
      "Epoch 2/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0039 - loss: 5.2943\n",
      "Epoch 2: val_accuracy improved from 0.00490 to 0.00503, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn_res_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.0037 - loss: 5.2947 - val_accuracy: 0.0050 - val_loss: 5.2933\n",
      "Epoch 3/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0044 - loss: 5.2948\n",
      "Epoch 3: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.0037 - loss: 5.2950 - val_accuracy: 0.0050 - val_loss: 5.2920\n",
      "Epoch 4/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0083 - loss: 5.2406\n",
      "Epoch 4: val_accuracy did not improve from 0.00503\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.0105 - loss: 5.1407 - val_accuracy: 0.0050 - val_loss: 17.3451\n",
      "Epoch 5/12\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0316 - loss: 4.6393\n",
      "Epoch 5: val_accuracy improved from 0.00503 to 0.02626, saving model to C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\cnn_res_best.keras\n",
      "\u001b[1m995/995\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.0513 - loss: 4.3334 - val_accuracy: 0.0263 - val_loss: 6.4429\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "cnn_res → Test Accuracy: 0.5251%\n",
      "\n",
      "============================================================\n",
      "FINAL TEST ACCURACY (real test images)\n",
      "============================================================\n",
      "cnn2     : 0.5251%\n",
      "cnn3     : 59.0140%\n",
      "cnn_res  : 0.5251%\n",
      "============================================================\n",
      "Label map saved → C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\label_to_char.json\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 0. Imports & GPU\n",
    "# -------------------------------------------------\n",
    "import os, random, warnings, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. GLOBAL SETTINGS (200 classes only)\n",
    "# -------------------------------------------------\n",
    "DATA_ROOT     = Path(r\"C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\data\\characters\")\n",
    "NOTEBOOK_ROOT = Path(r\"C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\")\n",
    "\n",
    "IMG_SIZE      = (64, 64)\n",
    "SAMPLE_CHARS  = 200\n",
    "TARGET_PER_CLASS = 200\n",
    "EPOCHS        = 12\n",
    "BATCH_SIZE    = 32\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Load folders\n",
    "# -------------------------------------------------\n",
    "char_folders = sorted([p for p in DATA_ROOT.iterdir() if p.is_dir()])[:SAMPLE_CHARS]\n",
    "print(f\"Selected {len(char_folders)} character folders (first 10):\")\n",
    "print([p.name for p in char_folders[:10]])\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3. Loader\n",
    "# -------------------------------------------------\n",
    "def safe_pil_read(p):\n",
    "    try:\n",
    "        return np.array(Image.open(p).convert('L'))\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] {p.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_class(folder: Path):\n",
    "    files = sorted(folder.glob(\"*.png\"))\n",
    "    imgs = []\n",
    "    for p in files:\n",
    "        arr = safe_pil_read(p)\n",
    "        if arr is not None:\n",
    "            imgs.append(cv2.resize(arr, IMG_SIZE, interpolation=cv2.INTER_AREA))\n",
    "    return np.array(imgs, dtype=np.uint8) if imgs else None\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4. Load + CONTINUOUS LABELS\n",
    "# -------------------------------------------------\n",
    "print(f\"\\nLoading {len(char_folders)} classes …\")\n",
    "train_X_list, train_y_list = [], []\n",
    "test_X_list , test_y_list  = [], []\n",
    "label_to_char = {}\n",
    "char_to_label = {}\n",
    "valid_class_idx = 0\n",
    "\n",
    "for folder in char_folders:\n",
    "    imgs = load_class(folder)\n",
    "    if imgs is None or len(imgs) < 40:\n",
    "        print(f\"  [SKIP] {folder.name} – <40 images\")\n",
    "        continue\n",
    "\n",
    "    label_to_char[valid_class_idx] = folder.name\n",
    "    char_to_label[folder.name] = valid_class_idx\n",
    "\n",
    "    n_train = 40\n",
    "    train_X_list.append(imgs[:n_train])\n",
    "    train_y_list.extend([valid_class_idx] * n_train)\n",
    "\n",
    "    if len(imgs) > n_train:\n",
    "        test_X_list.append(imgs[n_train:])\n",
    "        test_y_list.extend([valid_class_idx] * (len(imgs) - n_train))\n",
    "\n",
    "    valid_class_idx += 1\n",
    "\n",
    "if not train_X_list:\n",
    "    raise RuntimeError(\"No valid classes!\")\n",
    "\n",
    "train_X = np.concatenate(train_X_list)[..., np.newaxis] / 255.0\n",
    "train_y = np.array(train_y_list, dtype=np.int32)\n",
    "test_X = np.concatenate(test_X_list)[..., np.newaxis] / 255.0 if test_X_list else None\n",
    "test_y = np.array(test_y_list, dtype=np.int32) if test_y_list else None\n",
    "\n",
    "n_classes = len(label_to_char)\n",
    "print(f\"Valid classes: {n_classes}\")\n",
    "print(f\"Train: {train_X.shape}  Test: {test_X.shape if test_X is not None else 'None'}\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5. Augmentation\n",
    "# -------------------------------------------------\n",
    "def random_transform(img):\n",
    "    img = (img.squeeze() * 255).astype(np.uint8)\n",
    "    h, w = 64, 64\n",
    "    angle = random.choice([-12, -8, -4, 0, 4, 8, 12])\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "    shear = random.uniform(0.08, 0.22)\n",
    "    M = np.float32([[1, shear, 0], [0, 1, 0]]) if random.random() > 0.5 else np.float32([[1, 0, 0], [shear, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "    scale = random.uniform(0.82, 1.18)\n",
    "    nw, nh = int(w * scale), int(h * scale)\n",
    "    img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    top = bottom = left = right = 0\n",
    "    if nh < h: pad = (h - nh) // 2; top, bottom = pad, h - nh - pad\n",
    "    elif nh > h: crop = (nh - h) // 2; img = img[crop:crop + h, :]\n",
    "    if nw < w: pad = (w - nw) // 2; left, right = pad, w - nw - pad\n",
    "    elif nw > w: crop = (nw - w) // 2; img = img[:, crop:crop + w]\n",
    "    if any((top, bottom, left, right)):\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "    return (img / 255.0)[..., np.newaxis]\n",
    "\n",
    "def augment_to_target(class_imgs, target=200):\n",
    "    aug = []\n",
    "    while len(aug) < target:\n",
    "        for img in class_imgs:\n",
    "            aug.append(random_transform(img))\n",
    "            if len(aug) >= target: break\n",
    "    return np.array(aug[:target])\n",
    "\n",
    "print(\"Augmenting to 200 samples per class …\")\n",
    "aug_X, aug_y = [], []\n",
    "for label in range(n_classes):\n",
    "    idxs = np.where(train_y == label)[0]\n",
    "    class_imgs = train_X[idxs]\n",
    "    aug = augment_to_target(class_imgs, target=TARGET_PER_CLASS)\n",
    "    aug_X.append(aug)\n",
    "    aug_y.extend([label] * len(aug))\n",
    "\n",
    "train_X = np.concatenate(aug_X)\n",
    "train_y = np.array(aug_y, dtype=np.int32)\n",
    "print(f\"Final train: {train_X.shape}  ({train_X.shape[0]//n_classes} per class)\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 6. Train/Val Split\n",
    "# -------------------------------------------------\n",
    "train_X_final, val_X, train_y_final, val_y = train_test_split(\n",
    "    train_X, train_y, test_size=0.2, random_state=42, stratify=train_y\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 7. Model Builder\n",
    "# -------------------------------------------------\n",
    "def build_cnn(arch, input_shape=(64,64,1), n_classes=None):\n",
    "    if arch == 'cnn_res':\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        shortcut = x\n",
    "        x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, 3, padding='same', activation=None)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        shortcut = layers.Conv2D(64, 1, padding='same')(shortcut)\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "        model = models.Model(inputs, outputs, name='cnn_res')\n",
    "    else:\n",
    "        model = models.Sequential(name=arch)\n",
    "        model.add(layers.Conv2D(32, 3, activation='relu', input_shape=input_shape))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "        if arch == 'cnn2':\n",
    "            model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(128, activation='relu'))\n",
    "            model.add(layers.Dropout(0.4))\n",
    "        elif arch == 'cnn3':\n",
    "            model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Conv2D(128, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(256, activation='relu'))\n",
    "            model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 8. TRAIN LOOP (FIXED CHECKPOINT)\n",
    "# -------------------------------------------------\n",
    "results = {}\n",
    "histories = {}\n",
    "early_cb = callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
    "\n",
    "for arch in ['cnn2', 'cnn3', 'cnn_res']:\n",
    "    print(f\"\\n{'='*20} TRAINING {arch.upper()} {'='*20}\")\n",
    "    \n",
    "    # FIXED: Use f-string with current `arch`\n",
    "    checkpoint_cb = callbacks.ModelCheckpoint(\n",
    "        filepath=str(NOTEBOOK_ROOT / f\"{arch}_best.keras\"),\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    model = build_cnn(arch, n_classes=n_classes)\n",
    "    hist = model.fit(\n",
    "        train_X_final, train_y_final,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=(val_X, val_y),\n",
    "        callbacks=[checkpoint_cb, early_cb],\n",
    "        verbose=1\n",
    "    )\n",
    "    histories[arch] = hist.history\n",
    "\n",
    "    # Evaluate on real test set\n",
    "    if test_X is not None:\n",
    "        test_loss, test_acc = model.evaluate(test_X, test_y, verbose=0)\n",
    "        print(f\"{arch} → Test Accuracy: {test_acc:.4%}\")\n",
    "        results[arch] = test_acc\n",
    "    else:\n",
    "        acc = hist.history['val_accuracy'][-1]\n",
    "        print(f\"{arch} → Val Accuracy: {acc:.4%}\")\n",
    "        results[arch] = acc\n",
    "\n",
    "    model.save(str(NOTEBOOK_ROOT / f\"{arch}_final.keras\"))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 9. Summary\n",
    "# -------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL TEST ACCURACY (real test images)\")\n",
    "print(\"=\"*60)\n",
    "for arch, acc in results.items():\n",
    "    print(f\"{arch:8} : {acc:.4%}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 10. Save label map\n",
    "# -------------------------------------------------\n",
    "with open(NOTEBOOK_ROOT / \"label_to_char.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label_to_char, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Label map saved → {NOTEBOOK_ROOT / 'label_to_char.json'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
