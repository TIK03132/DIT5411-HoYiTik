{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd7f9b07-1d8c-4e79-87c3-e83bc71de75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.20.0\n",
      "GPU: []\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 1. Imports & GPU\n",
    "# -------------------------------------------------\n",
    "import os, random, warnings, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.random.set_seed(42); np.random.seed(42); random.seed(42)\n",
    "\n",
    "print(\"TF:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50191d3-8182-45f3-abeb-4c5f431c9e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 2. GLOBAL SETTINGS\n",
    "# -------------------------------------------------\n",
    "DATA_ROOT     = Path(r\"C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\\data\\characters\")\n",
    "NOTEBOOK_ROOT = Path(r\"C:\\Users\\TIK03\\Documents\\GitHub\\DIT5411-HoYiTik\\Assgnment\")\n",
    "\n",
    "IMG_SIZE      = (64, 64)\n",
    "SAMPLE_CHARS  = 100          # ← WORKS!\n",
    "TARGET_PER_CLASS = 200\n",
    "EPOCHS        = 8\n",
    "BATCH_SIZE    = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c42a0a4-79c0-4639-b1cd-69bbb7b10d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13065 character folders\n",
      "First 10: ['1', '10', '100', '1000', '10000', '10001', '10002', '10003', '10004', '10005']\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 3. Verify folder\n",
    "# -------------------------------------------------\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(DATA_ROOT)\n",
    "\n",
    "subfolders = [p for p in DATA_ROOT.iterdir() if p.is_dir()]\n",
    "print(f\"Found {len(subfolders)} character folders\")\n",
    "print(\"First 10:\", [p.name for p in subfolders[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c657446-cd24-40b3-aeab-41217904c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 4. PIL loader (Chinese filenames)\n",
    "# -------------------------------------------------\n",
    "def safe_pil_read(p):\n",
    "    try:\n",
    "        return np.array(Image.open(p).convert('L'))\n",
    "    except Exception as e:\n",
    "        print(f\"  [WARN] {p.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_class(folder: Path):\n",
    "    files = sorted(folder.glob(\"*.png\"))\n",
    "    imgs = []\n",
    "    for p in files:\n",
    "        arr = safe_pil_read(p)\n",
    "        if arr is not None:\n",
    "            imgs.append(cv2.resize(arr, IMG_SIZE, interpolation=cv2.INTER_AREA))\n",
    "    return np.array(imgs, dtype=np.uint8) if imgs else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e2a1d3-1b6d-4cb4-ad23-b02e3a745ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading 100 classes …\n",
      "Train: (4000, 64, 64, 1)  Test: (1260, 64, 64, 1)\n",
      "Classes: 100\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 5. Load & split (40 train / rest test)\n",
    "# -------------------------------------------------\n",
    "char_folders = sorted([p for p in DATA_ROOT.iterdir() if p.is_dir()])\n",
    "if SAMPLE_CHARS:\n",
    "    char_folders = random.sample(char_folders, SAMPLE_CHARS)\n",
    "\n",
    "print(f\"\\nLoading {len(char_folders)} classes …\")\n",
    "\n",
    "train_X_list, train_y_list = [], []\n",
    "test_X_list , test_y_list  = [], []\n",
    "label_to_char = {}\n",
    "char_to_label = {}\n",
    "\n",
    "for idx, folder in enumerate(char_folders):\n",
    "    imgs = load_class(folder)\n",
    "    if imgs is None or len(imgs) < 40:\n",
    "        print(f\"  [SKIP] {folder.name} – <40 images\")\n",
    "        continue\n",
    "\n",
    "    label_to_char[idx] = folder.name\n",
    "    char_to_label[folder.name] = idx\n",
    "\n",
    "    n_train = min(40, len(imgs))\n",
    "    train_X_list.append(imgs[:n_train])\n",
    "    train_y_list.extend([idx] * n_train)\n",
    "\n",
    "    if len(imgs) > n_train:\n",
    "        test_X_list.append(imgs[n_train:])\n",
    "        test_y_list.extend([idx] * (len(imgs) - n_train))\n",
    "\n",
    "if not train_X_list:\n",
    "    raise RuntimeError(\"No valid classes!\")\n",
    "\n",
    "train_X = np.concatenate(train_X_list)[..., np.newaxis] / 255.0\n",
    "train_y = np.array(train_y_list, dtype=np.int32)\n",
    "\n",
    "test_X = np.concatenate(test_X_list)[..., np.newaxis] / 255.0 if test_X_list else None\n",
    "test_y = np.array(test_y_list, dtype=np.int32) if test_y_list else None\n",
    "\n",
    "print(f\"Train: {train_X.shape}  Test: {test_X.shape if test_X is not None else 'None'}\")\n",
    "print(f\"Classes: {len(np.unique(train_y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717d6271-0a3a-40f1-848e-385469d3544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 6. FIXED Augmentation (64x64 guaranteed)\n",
    "# -------------------------------------------------\n",
    "def random_transform(img):\n",
    "    img = (img.squeeze() * 255).astype(np.uint8)\n",
    "    h, w = 64, 64\n",
    "\n",
    "    # rotation\n",
    "    angle = random.choice([-12, -8, -4, 0, 4, 8, 12])\n",
    "    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "    # shear\n",
    "    shear = random.uniform(0.08, 0.22)\n",
    "    M = np.float32([[1, shear, 0], [0, 1, 0]]) if random.random() > 0.5 else np.float32([[1, 0, 0], [shear, 1, 0]])\n",
    "    img = cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "    # scale\n",
    "    scale = random.uniform(0.82, 1.18)\n",
    "    nw, nh = int(w * scale), int(h * scale)\n",
    "    img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # pad/crop to 64x64\n",
    "    top = bottom = left = right = 0\n",
    "    if nh < h:\n",
    "        pad = (h - nh) // 2\n",
    "        top, bottom = pad, h - nh - pad\n",
    "    elif nh > h:\n",
    "        crop = (nh - h) // 2\n",
    "        img = img[crop:crop + h, :]\n",
    "    if nw < w:\n",
    "        pad = (w - nw) // 2\n",
    "        left, right = pad, w - nw - pad\n",
    "    elif nw > w:\n",
    "        crop = (nw - w) // 2\n",
    "        img = img[:, crop:crop + w]\n",
    "\n",
    "    if any((top, bottom, left, right)):\n",
    "        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=255)\n",
    "\n",
    "    return (img / 255.0)[..., np.newaxis]\n",
    "\n",
    "def augment_to_target(class_imgs, target=200):\n",
    "    aug = []\n",
    "    while len(aug) < target:\n",
    "        for img in class_imgs:\n",
    "            aug.append(random_transform(img))\n",
    "            if len(aug) >= target:\n",
    "                break\n",
    "    return np.array(aug[:target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7579e93b-8701-4686-bce1-53056e89c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting to 200 samples per class …\n",
      "Final train: (20000, 64, 64, 1)  (200 per class)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 7. Build augmented set\n",
    "# -------------------------------------------------\n",
    "print(\"Augmenting to 200 samples per class …\")\n",
    "aug_X, aug_y = [], []\n",
    "\n",
    "for label in np.unique(train_y):\n",
    "    idxs = np.where(train_y == label)[0]\n",
    "    class_imgs = train_X[idxs]\n",
    "    aug = augment_to_target(class_imgs, target=TARGET_PER_CLASS)\n",
    "    aug_X.append(aug)\n",
    "    aug_y.extend([label] * len(aug))\n",
    "\n",
    "train_X = np.concatenate(aug_X)\n",
    "train_y = np.array(aug_y, dtype=np.int32)\n",
    "\n",
    "print(f\"Final train: {train_X.shape}  ({train_X.shape[0]//len(np.unique(train_y))} per class)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d95dcc7f-5ba9-4d94-8736-5ea46239eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# 8. FIXED CNN models (cnn_res now works!)\n",
    "# -------------------------------------------------\n",
    "def build_cnn(arch, input_shape=(64,64,1), n_classes=None):\n",
    "    if arch == 'cnn_res':\n",
    "        # Build with Functional API from scratch\n",
    "        inputs = layers.Input(shape=input_shape)\n",
    "        x = layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "        # Residual block\n",
    "        shortcut = x\n",
    "        x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Conv2D(64, 3, padding='same', activation=None)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        shortcut = layers.Conv2D(64, 1, padding='same')(shortcut)\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        x = layers.Activation('relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "        x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(256, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        outputs = layers.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "        model = models.Model(inputs, outputs, name='cnn_res')\n",
    "    else:\n",
    "        model = models.Sequential(name=arch)\n",
    "        model.add(layers.Conv2D(32, 3, activation='relu', input_shape=input_shape))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "        if arch == 'cnn2':\n",
    "            model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(128, activation='relu'))\n",
    "            model.add(layers.Dropout(0.4))\n",
    "        elif arch == 'cnn3':\n",
    "            model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Conv2D(128, 3, activation='relu'))\n",
    "            model.add(layers.MaxPooling2D(2))\n",
    "            model.add(layers.Flatten())\n",
    "            model.add(layers.Dense(256, activation='relu'))\n",
    "            model.add(layers.Dropout(0.5))\n",
    "\n",
    "        model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a1269-9ef7-479b-9bda-5c9431ff786d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TRAINING CNN2 ===\n",
      "Epoch 1/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.0597 - loss: 4.0951 - val_accuracy: 0.0000e+00 - val_loss: 7.0052\n",
      "Epoch 2/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.2171 - loss: 2.9282 - val_accuracy: 0.0000e+00 - val_loss: 14.5416\n",
      "Epoch 3/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.3297 - loss: 2.3458 - val_accuracy: 0.0000e+00 - val_loss: 20.5258\n",
      "Epoch 4/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.4254 - loss: 1.9257 - val_accuracy: 0.0000e+00 - val_loss: 33.2114\n",
      "Epoch 5/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.5011 - loss: 1.6171 - val_accuracy: 0.0000e+00 - val_loss: 39.6567\n",
      "Epoch 6/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.5512 - loss: 1.4430 - val_accuracy: 0.0000e+00 - val_loss: 25.3973\n",
      "Epoch 7/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.5952 - loss: 1.2738 - val_accuracy: 0.0000e+00 - val_loss: 45.0315\n",
      "Epoch 8/8\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.6202 - loss: 1.1710 - val_accuracy: 0.0000e+00 - val_loss: 50.2658\n",
      "cnn2 → Val Acc: 0.0000%\n",
      "\n",
      "=== TRAINING CNN3 ===\n",
      "Epoch 1/8\n",
      "\u001b[1m247/500\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.0233 - loss: 4.4769"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 9. Train all 3 models\n",
    "# -------------------------------------------------\n",
    "results, histories = {}, {}\n",
    "n_classes = len(np.unique(train_y))\n",
    "\n",
    "for arch in ['cnn2', 'cnn3', 'cnn_res']:\n",
    "    print(f\"\\n=== TRAINING {arch.upper()} ===\")\n",
    "    model = build_cnn(arch, n_classes=n_classes)\n",
    "\n",
    "    hist = model.fit(train_X, train_y,\n",
    "                     epochs=EPOCHS,\n",
    "                     batch_size=BATCH_SIZE,\n",
    "                     validation_split=0.2,\n",
    "                     verbose=1)\n",
    "    histories[arch] = hist\n",
    "\n",
    "    acc = hist.history['val_accuracy'][-1]\n",
    "    results[arch] = acc\n",
    "    print(f\"{arch} → Val Acc: {acc:.4%}\")\n",
    "\n",
    "    model.save(f\"{NOTEBOOK_ROOT}/{arch}_model.keras\")  # ← .keras (modern format)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
